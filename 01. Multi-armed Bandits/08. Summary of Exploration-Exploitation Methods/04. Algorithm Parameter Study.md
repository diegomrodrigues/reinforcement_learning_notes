## Sum√°rio e An√°lise Comparativa de Algoritmos Multi-Armed Bandit

### Introdu√ß√£o
Este cap√≠tulo consolidou v√°rios m√©todos fundamentais para lidar com o dilema explora√ß√£o-explota√ß√£o em problemas de *k-armed bandit*. Agora, examinaremos como comparar esses algoritmos de forma justa, especialmente considerando que cada um possui um ou mais par√¢metros que influenciam significativamente seu comportamento [^42].

### Compara√ß√£o Algor√≠tmica e Estudos de Par√¢metros
Uma pergunta natural √©: qual desses m√©todos √© o melhor? Embora uma resposta universal seja elusiva, podemos comparar esses algoritmos numericamente no *10-armed testbed* introduzido anteriormente [^28]. No entanto, para realizar uma compara√ß√£o significativa, devemos reconhecer que o desempenho de cada algoritmo depende crucialmente da configura√ß√£o de seus par√¢metros.

A an√°lise de desempenho n√£o deve se limitar a um √∫nico valor de par√¢metro, mas sim considerar o desempenho em fun√ß√£o do par√¢metro. Gr√°ficos que mostram a trajet√≥ria de aprendizagem ao longo do tempo (curvas de aprendizado) para cada algoritmo e configura√ß√£o de par√¢metro s√£o √∫teis, mas podem se tornar complexos para compara√ß√µes abrangentes.

Uma abordagem mais concisa √© resumir uma curva de aprendizado completa por seu valor m√©dio ao longo de um per√≠odo de tempo fixo, como os primeiros 1000 passos [^42]. Esse valor √© proporcional √† √°rea sob a curva de aprendizado e fornece uma medida geral do desempenho do algoritmo. Plotar essa medida em fun√ß√£o do valor do par√¢metro resulta em um *parameter study* [^42].

> üí° **Exemplo Num√©rico:**
>
> Considere um algoritmo epsilon-greedy com $\epsilon \in [0, 1]$. Simulamos esse algoritmo no *10-armed testbed* por 1000 passos para cada valor de $\epsilon$ em $\{0.01, 0.1, 0.2, 0.3, 0.4, 0.5\}$. Calculamos o retorno m√©dio para cada $\epsilon$ e plotamos os resultados.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Fun√ß√£o para simular o 10-armed testbed
> def simulate_bandit(epsilon, steps=1000):
>     q_star = np.random.normal(0, 1, 10) # Valores reais das a√ß√µes (desconhecidos)
>     q_estimates = np.zeros(10)  # Estimativas iniciais das a√ß√µes
>     counts = np.zeros(10)       # Contagem de vezes que cada a√ß√£o foi selecionada
>     rewards = []
>
>     for _ in range(steps):
>         if np.random.rand() < epsilon:
>             # Explora√ß√£o: Escolhe uma a√ß√£o aleat√≥ria
>             action = np.random.choice(10)
>         else:
>             # Explota√ß√£o: Escolhe a a√ß√£o com a maior estimativa
>             action = np.argmax(q_estimates)
>
>         # Recebe a recompensa (com ru√≠do)
>         reward = np.random.normal(q_star[action], 1)
>         rewards.append(reward)
>
>         # Atualiza a estimativa e a contagem
>         counts[action] += 1
>         q_estimates[action] += (reward - q_estimates[action]) / counts[action]
>
>     return np.mean(rewards)
>
> # Valores de epsilon a serem testados
> epsilons = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]
>
> # Simula√ß√µes para cada epsilon
> avg_rewards = [simulate_bandit(epsilon) for epsilon in epsilons]
>
> # Plota os resultados
> plt.figure(figsize=(10, 6))
> plt.plot(epsilons, avg_rewards, marker='o')
> plt.title("Parameter Study para Epsilon-Greedy")
> plt.xlabel("Valor de Epsilon")
> plt.ylabel("Retorno M√©dio (1000 passos)")
> plt.grid(True)
> plt.show()
> ```
>
> Este gr√°fico demonstraria como o retorno m√©dio varia com diferentes valores de $\epsilon$, exibindo potencialmente um formato de "U invertido". Um valor muito baixo de $\epsilon$ levaria a pouca explora√ß√£o, enquanto um valor muito alto levaria a muita explora√ß√£o em detrimento da explota√ß√£o das melhores a√ß√µes.

#### Caracter√≠sticas dos *Parameter Studies*
Em um *parameter study*, os valores dos par√¢metros s√£o tipicamente variados por fatores de dois e apresentados em uma escala logar√≠tmica [^42]. Isso permite uma an√°lise abrangente do impacto de diferentes magnitudes dos par√¢metros. Os gr√°ficos resultantes frequentemente exibem formatos caracter√≠sticos de "U invertido" [^42].

![Parameter study comparing bandit algorithms, showing average reward over 1000 steps as a function of algorithm-specific parameters.](./../images/image2.png)

Essa forma reflete a exist√™ncia de um valor de par√¢metro intermedi√°rio ideal para muitos algoritmos. Valores muito pequenos podem levar a explora√ß√£o insuficiente, enquanto valores muito grandes podem resultar em explota√ß√£o prematura de a√ß√µes sub√≥timas.

Para formalizar essa observa√ß√£o, podemos definir um conceito para caracterizar o valor √≥timo de um par√¢metro.

**Defini√ß√£o 1 (Par√¢metro √ìtimo):** Seja $A$ um algoritmo multi-armed bandit com um par√¢metro $\theta \in \Theta$, onde $\Theta$ √© o espa√ßo de par√¢metros. Seja $R_A(\theta)$ o retorno m√©dio de $A$ com par√¢metro $\theta$ ao longo de um horizonte de tempo $T$. Definimos o *par√¢metro √≥timo* $\theta^*$ como:

$$\theta^* = \arg\max_{\theta \in \Theta} R_A(\theta)$$

O par√¢metro √≥timo $\theta^*$ representa o valor que maximiza o desempenho do algoritmo $A$ no ambiente especificado.

#### Sensibilidade ao Par√¢metro
Ao avaliar um m√©todo, n√£o devemos apenas considerar seu desempenho na configura√ß√£o de par√¢metro ideal, mas tamb√©m sua *sensibilidade* ao valor do par√¢metro [^43]. Um algoritmo robusto deve manter um desempenho razo√°vel em uma ampla gama de valores de par√¢metro. M√©todos que s√£o excessivamente sens√≠veis a pequenas varia√ß√µes nos par√¢metros podem ser menos confi√°veis em situa√ß√µes pr√°ticas [^43].

Um algoritmo √© considerado robusto ou razoavelmente insens√≠vel se seu desempenho se mantiver bom em uma ampla gama de par√¢metros. Por exemplo, um algoritmo cujo desempenho se mant√©m bom ao variar os par√¢metros em uma ordem de magnitude √© geralmente prefer√≠vel.

Para quantificar a sensibilidade, podemos definir uma medida de varia√ß√£o do desempenho em torno do par√¢metro √≥timo.

**Defini√ß√£o 2 (Sensibilidade ao Par√¢metro):** Seja $A$ um algoritmo multi-armed bandit com par√¢metro √≥timo $\theta^*$. Definimos a *sensibilidade* de $A$ em torno de $\theta^*$ como a varia√ß√£o do retorno m√©dio $R_A(\theta)$ em um intervalo $[\theta^*/c, c\theta^*]$ para alguma constante $c > 1$. A sensibilidade $S_A(\theta^*, c)$ pode ser quantificada como:

$$S_A(\theta^*, c) = \frac{R_A(\theta^*) - \min_{\theta \in [\theta^*/c, c\theta^*]} R_A(\theta)}{R_A(\theta^*)}$$

Um valor baixo de $S_A(\theta^*, c)$ indica que o algoritmo √© relativamente insens√≠vel a varia√ß√µes no par√¢metro em torno do valor √≥timo.

Para ilustrar como a sensibilidade pode ser analisada, considere o seguinte exemplo.

**Exemplo:** Suponha que um algoritmo $A$ tenha um par√¢metro √≥timo $\theta^* = 1$. Queremos analisar a sensibilidade em torno deste ponto com $c = 2$.

I.  Primeiro, definimos o intervalo de an√°lise: $[\theta^*/c, c\theta^*] = [1/2, 2]$.

II.  Em seguida, avaliamos o retorno m√©dio $R_A(\theta)$ para todos os $\theta$ dentro do intervalo $[1/2, 2]$.

III. Encontramos o valor m√≠nimo do retorno m√©dio dentro do intervalo: $\min_{\theta \in [1/2, 2]} R_A(\theta)$.

IV.  Suponha que o retorno m√©dio no ponto √≥timo seja $R_A(1) = 10$ e o valor m√≠nimo dentro do intervalo seja $\min_{\theta \in [1/2, 2]} R_A(\theta) = 8$.

V.  Calculamos a sensibilidade:

    $$S_A(1, 2) = \frac{10 - 8}{10} = 0.2$$

VI.  Este valor de $S_A(1, 2) = 0.2$ indica que o desempenho do algoritmo decai em 20% no pior caso dentro do intervalo analisado.

‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Continuando com o exemplo anterior, vamos considerar um algoritmo UCB com um par√¢metro $c$. Suponha que ap√≥s um *parameter study*, o valor √≥timo de $c$ seja encontrado como $c^* = 0.5$. O retorno m√©dio neste ponto √© $R_A(0.5) = 12$. Agora, vamos calcular a sensibilidade para $c = 2$.
>
> I.  O intervalo de an√°lise √© $[0.5/2, 2*0.5] = [0.25, 1]$.
> II.  Simulamos o algoritmo UCB para diversos valores de $c$ dentro desse intervalo.
> III.  Suponha que o menor retorno m√©dio dentro do intervalo seja encontrado em $c = 0.25$, com um retorno m√©dio de $R_A(0.25) = 9$.
> IV.  Calculamos a sensibilidade:
>     $$S_A(0.5, 2) = \frac{12 - 9}{12} = 0.25$$
>
> Isso significa que o desempenho do algoritmo UCB diminui em 25% no pior caso quando $c$ varia por um fator de 2 em torno do valor √≥timo. Isso pode ser considerado uma sensibilidade moderada.
>
> A visualiza√ß√£o ajuda a entender como o desempenho varia dentro do intervalo definido e auxilia na interpreta√ß√£o da sensibilidade calculada.

Al√©m da sensibilidade, √© importante considerar a facilidade com que o par√¢metro √≥timo pode ser encontrado. Podemos introduzir o conceito de *custo de otimiza√ß√£o*.

**Defini√ß√£o 3 (Custo de Otimiza√ß√£o):** Seja $A$ um algoritmo multi-armed bandit com um par√¢metro $\theta$. O *custo de otimiza√ß√£o* $C_A$ √© o esfor√ßo computacional (e.g., n√∫mero de experimentos, tempo de computa√ß√£o) necess√°rio para encontrar um valor de $\theta$ que resulte em um desempenho "suficientemente bom", ou seja, dentro de uma margem aceit√°vel do desempenho √≥timo.

Algoritmos com custos de otimiza√ß√£o elevados podem ser menos pr√°ticos, mesmo que possuam bom desempenho com o par√¢metro ideal.

> üí° **Exemplo Num√©rico:**
>
> Considere dois algoritmos para um problema de *multi-armed bandit*. O Algoritmo A tem um desempenho ligeiramente superior quando o par√¢metro √© afinado com precis√£o (retorno m√©dio de 10), mas requer uma busca exaustiva com 1000 itera√ß√µes para encontrar o par√¢metro ideal. O Algoritmo B tem um desempenho ligeiramente inferior (retorno m√©dio de 9.5), mas pode ser otimizado em apenas 100 itera√ß√µes.
>
> Num ambiente com recursos computacionais limitados, o Algoritmo B seria provavelmente a escolha mais pr√°tica, apesar do seu desempenho ligeiramente inferior, devido ao seu custo de otimiza√ß√£o significativamente menor. Isso destaca o *trade-off* entre desempenho e custo de otimiza√ß√£o.
>
> ```mermaid
> graph LR
>     A[Algoritmo A] --> B(Desempenho: 10, Custo: 1000)
>     C[Algoritmo B] --> D(Desempenho: 9.5, Custo: 100)
>     E[Recursos Limitados] --> F{Escolher A ou B?}
>     F --> |Custo < Limite| D
>     F --> |Custo > Limite| D
> ```

Para ilustrar como o custo de otimiza√ß√£o pode afetar a escolha do algoritmo, considere a seguinte prova.

**Prova (Trade-off entre desempenho e custo de otimiza√ß√£o):**

Suponha que temos dois algoritmos: $A_1$ e $A_2$. O algoritmo $A_1$ tem um par√¢metro √≥timo $\theta_1^*$ e atinge um retorno m√©dio m√°ximo de $R_{A_1}(\theta_1^*) = R_{max}$. O algoritmo $A_2$ tem um par√¢metro √≥timo $\theta_2^*$ e atinge um retorno m√©dio m√°ximo de $R_{A_2}(\theta_2^*) = 0.95 R_{max}$, ou seja, 95% do retorno m√°ximo de $A_1$. No entanto, o custo para encontrar $\theta_1^*$ √© muito alto (e.g., requer um n√∫mero exponencial de experimentos), enquanto encontrar $\theta_2^*$ √© muito mais f√°cil (e.g., requer um n√∫mero linear de experimentos).

I.  Definimos o esfor√ßo computacional como o n√∫mero de experimentos necess√°rios para encontrar um par√¢metro que resulte em um desempenho pr√≥ximo do √≥timo. Seja $C_{A_1}$ o custo de otimiza√ß√£o para $A_1$ e $C_{A_2}$ o custo de otimiza√ß√£o para $A_2$. Assumimos que $C_{A_1} >> C_{A_2}$.

II.  Se temos recursos computacionais limitados, pode ser mais vantajoso usar o algoritmo $A_2$, mesmo que seu desempenho √≥timo seja ligeiramente inferior. Isso porque o custo de otimiza√ß√£o de $A_1$ pode ser proibitivo.

III. Portanto, mesmo que $R_{A_1}(\theta_1^*) > R_{A_2}(\theta_2^*)$, a escolha do algoritmo ideal depende do trade-off entre o desempenho e o custo de otimiza√ß√£o. Em situa√ß√µes pr√°ticas, a escolha recai sobre o algoritmo que oferece o melhor desempenho dentro das restri√ß√µes de recursos computacionais dispon√≠veis.

IV. Assim, provamos que o custo de otimiza√ß√£o √© um fator crucial na escolha de um algoritmo, especialmente quando os recursos computacionais s√£o limitados. ‚ñ†

### Conclus√£o
A an√°lise comparativa de algoritmos de *multi-armed bandit* exige uma considera√ß√£o cuidadosa do desempenho em fun√ß√£o dos par√¢metros, usando *parameter studies*. A identifica√ß√£o de um valor de par√¢metro ideal e a avalia√ß√£o da sensibilidade do desempenho √†s varia√ß√µes do par√¢metro s√£o etapas essenciais para selecionar o algoritmo mais adequado para uma tarefa espec√≠fica [^43]. No *10-armed testbed*, o algoritmo UCB parece ter um bom desempenho em geral [^43]. A introdu√ß√£o de medidas formais como o par√¢metro √≥timo, a sensibilidade e o custo de otimiza√ß√£o permite uma an√°lise mais rigorosa e comparativa dos algoritmos.

### Refer√™ncias
[^28]: Se√ß√£o 2.3, "The 10-armed Testbed"
[^42]: Se√ß√£o 2.10, "Summary"
[^43]: Se√ß√£o 2.10, "Summary"
<!-- END -->